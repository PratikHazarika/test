{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BertEmbedding.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOKLO1gdHYN34mRm9+CXuC3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Loading the data"],"metadata":{"id":"6UHCWG8dcVOP"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer\n","\n","from simpletransformers.language_representation import RepresentationModel\n","from tensorflow.keras.utils import to_categorical\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive/', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w03OiHA7V2qS","executionInfo":{"status":"ok","timestamp":1657173755509,"user_tz":-330,"elapsed":5576,"user":{"displayName":"Pratik Hazarika","userId":"04317859684722913646"}},"outputId":"39b35a09-2cfc-46f3-c197-342612508d76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}]},{"cell_type":"markdown","source":["# Cleaning the data"],"metadata":{"id":"bfVMyyE2cRFJ"}},{"cell_type":"code","source":["df = pd.read_csv ('gdrive/MyDrive/Colab Notebooks/Sentiment Analysis/tweet_emotions.csv') # loading the dataset\n","df.drop('tweet_id', inplace = True, axis = 1) # removing tweet_id column\n","df.dropna(inplace=True) # removing empty values\n","df.rename(columns = {'content':'sentence'}, inplace = True)"],"metadata":{"id":"LUHxqP3EV4Bw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CSV -> Sentence"],"metadata":{"id":"ubYc-GI5cYUk"}},{"cell_type":"code","source":["cols_as_np = df[df.columns[0:]].to_numpy() # converting pd into np\n"," \n","emotions = [data[0] for data in cols_as_np] # extracing sentences\n","sentences = [data[1] for data in cols_as_np] # extracting emotions"],"metadata":{"id":"iBZRFIFkYXFv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Splitting train, test, val data"],"metadata":{"id":"LMtxgqxle8yA"}},{"cell_type":"code","source":["train_sentences, test_sentences, train_emotions, test_emotions = train_test_split(sentences, emotions, test_size=0.2, random_state=1)\n","train_sentences, val_sentences, train_emotions, val_emotions = train_test_split(train_sentences, train_emotions, test_size=0.25, random_state=1) "],"metadata":{"id":"YG57YlUfb4OM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Emotions -> Categorical\n"],"metadata":{"id":"VDiVIfNigSR1"}},{"cell_type":"code","source":["emotions = np.unique(emotions) #getting the unique intents\n","\n","encoded_emotions_dict = {'anger':0, 'boredom':1, 'empty':2, 'enthusiasm':3, 'fun':4, 'happiness':5,\n","                'hate':6, 'love':7, 'neutral':8, 'relief':9, 'sadness':10, 'surprise':11, 'worry':12}\n","\n","for index, emotion in enumerate(train_emotions):\n","  if emotion in encoded_emotions_dict:\n","    train_emotions[index] = encoded_emotions_dict[emotion]\n","\n","for index, emotion in enumerate(test_emotions):\n","  if emotion in encoded_emotions_dict:\n","    test_emotions[index] = encoded_emotions_dict[emotion]\n","\n","for index, emotion in enumerate(val_emotions):\n","  if emotion in encoded_emotions_dict:\n","    val_emotions[index] = encoded_emotions_dict[emotion]\n","\n","categorical_train_emotions = to_categorical(train_emotions) # y_train\n","categorical_test_emotions = to_categorical(test_emotions) # y_test\n","categorical_val_emotions = to_categorical(val_emotions)"],"metadata":{"id":"9WvwgDrbfp-2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tokenizing, Padding & Dictionary"],"metadata":{"id":"6jNZYTNuPpoz"}},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\", do_lower_case=True, pad_token=\"[PAD]\") # tokenizing each sentennce\n","\n","for sentence in train_sentences:\n","  token = tokenizer.tokenize(sentence) # tokenizing each word in the sentence\n","  token = ['[CLS]'] + token + ['[SEP]']\n","  tokenizer.convert_tokens_to_ids(token) # giving id numbers to each word\n","  print(token)\n","  break\n","\n","dictionary = tokenizer.vocab\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESCbLyrtPyrj","executionInfo":{"status":"ok","timestamp":1657174915409,"user_tz":-330,"elapsed":2416,"user":{"displayName":"Pratik Hazarika","userId":"04317859684722913646"}},"outputId":"cfded931-cbb4-42c6-846c-24cefb9a2566"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['[CLS]', '@', 's', '##g', '##beat', ':', 'k', '##wang', '##ho', '##ck', '@', 'v', '##alk', '##yr', '##ies', '##life', '@', 'ka', '##hh', '##ong', '##ta', '##y', '@', 'j', '##ere', '##my', '##8', '##9', '##6', '##32', 'it', 'is', 'the', 'ha', '##o', 'da', 'z', '##a', 'ji', 'p', '##a', '?', '?', 'i', 'miss', 'the', 'food', 'there', 'so', 'much', '?', '?', '[SEP]']\n"]}]},{"cell_type":"markdown","source":["# Encoding\n"],"metadata":{"id":"GBKwuiggoJon"}},{"cell_type":"code","source":["ls = [len(sentence.split()) for sentence in train_sentences]\n","max_len = int(np.percentile(ls, 98))\n","\n","def encode(sentence):\n","  encoding = tokenizer.encode_plus(\n","      sentence, \n","      max_length = max_len,\n","      add_special_tokens = True,\n","      pad_to_max_length = True,\n","      return_attention_mask = True,\n","      return_token_type_ids = False,\n","      verbose = True\n","  )\n","\n","  return encoding\n","\n","train_sentences_encoded = [encode(sentence) for sentence in train_sentences]\n","test_sentences_encoded = [encode(sentence) for sentence in test_sentences]\n","\n","# train_emotions_encoded = [encode(sentence) for sentence in train_emotions]\n","# test_emotions_encoded = [encode(sentence) for sentence in test_emotions]\n","\n","# val_sentences_encoded = [encode(sentence) for sentence in val_sentences]\n","# val_emotions_encoded = [encode(sentence) for sentence in val_emotions]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":480},"id":"MAK5PPKgAtIq","executionInfo":{"status":"error","timestamp":1657181803544,"user_tz":-330,"elapsed":6034,"user":{"displayName":"Pratik Hazarika","userId":"04317859684722913646"}},"outputId":"4f6bc3b9-a989-4c38-94d0-8967862e245b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-101-ae97d255fcec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# train_emotions_encoded = [encode(sentence) for sentence in train_emotions]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtest_emotions_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_emotions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# val_sentences_encoded = [encode(sentence) for sentence in val_sentences]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-101-ae97d255fcec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# train_emotions_encoded = [encode(sentence) for sentence in train_emotions]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtest_emotions_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_emotions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# val_sentences_encoded = [encode(sentence) for sentence in val_sentences]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-101-ae97d255fcec>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mreturn_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mreturn_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2604\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2605\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2606\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2607\u001b[0m         )\n\u001b[1;32m   2608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         )\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0mis_pretokenized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_split_into_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         )\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"]}]},{"cell_type":"code","source":["input_ids = []\n","input_mask = []\n","\n","test_input_ids = []\n","test_input_mask = []\n","\n","for encoding in train_sentences_encoded:\n","  for input_id in encoding['input_ids']:\n","    input_ids.append(input_id)\n","\n","  for mask_value in encoding['attention_mask']:\n","    input_mask.append(mask_value)\n","\n"," for encoding in test_sentences_encoded:\n","  for input_id in encoding['input_ids']:\n","    input_ids.append(input_id)\n","\n","  for mask_value in encoding['attention_mask']:\n","    input_mask.append(mask_value) "],"metadata":{"id":"ZMOtyuYGVJZj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Embedding"],"metadata":{"id":"-035izRVoNC8"}},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"967c9AL9V-Hp"}},{"cell_type":"code","source":["import tensorflow as tf\n","import bert\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.initializers import TruncatedNormal\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.metrics import CategoricalAccuracy\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Input, Dense"],"metadata":{"id":"oltmOfCkV96Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# input_ids = x_train['input_ids']\n","# attention_mask = x_train['attention_mask']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0BVuYBbmdya-","executionInfo":{"status":"ok","timestamp":1657177544265,"user_tz":-330,"elapsed":604,"user":{"displayName":"Pratik Hazarika","userId":"04317859684722913646"}},"outputId":"9382722a-73f5-499e-a4f6-d4bd5f1a76be"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(24000, 70), dtype=int32, numpy=\n","array([[  101,   137,   188, ...,     0,     0,     0],\n","       [  101,   137, 11148, ...,     0,     0,     0],\n","       [  101,   146,  1125, ...,     0,     0,     0],\n","       ...,\n","       [  101,  1921,  5837, ...,     0,     0,     0],\n","       [  101,  8325,  2537, ...,     0,     0,     0],\n","       [  101,   137,  4267, ...,     0,     0,     0]], dtype=int32)>"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["# max_len = 70\n","\n","input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n","input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n","embeddings = bert(input_ids,attention_mask = input_mask)[0]\n","\n","out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n","out = Dense(128, activation='relu')(out)\n","out = tf.keras.layers.Dropout(0.1)(out)\n","out = Dense(32,activation = 'relu')(out)\n","y = Dense(6,activation = 'sigmoid')(out)\n","\n","model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n","model.layers[2].trainable = True"],"metadata":{"id":"eIoW_MdOV9ba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = Adam(\n","    learning_rate=5e-05, # this learning rate is for bert model , taken from huggingface website \n","    epsilon=1e-08,\n","    decay=0.01,\n","    clipnorm=1.0)\n","# Set loss and metrics\n","loss =CategoricalCrossentropy(from_logits = True)\n","metric = CategoricalAccuracy('balanced_accuracy'),\n","# Compile the model\n","model.compile(\n","    optimizer = optimizer,\n","    loss = loss, \n","    metrics = metric)"],"metadata":{"id":"eC4vWpdBbDyc","executionInfo":{"status":"ok","timestamp":1657184683432,"user_tz":-330,"elapsed":539,"user":{"displayName":"Pratik Hazarika","userId":"04317859684722913646"}}},"execution_count":115,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZoCjkFN7Yii","executionInfo":{"status":"ok","timestamp":1657185094340,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pratik Hazarika","userId":"04317859684722913646"}},"outputId":"172c91e2-1db8-46be-9247-800235072231"},"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"text/plain":["keras.engine.keras_tensor.KerasTensor"]},"metadata":{},"execution_count":122}]},{"cell_type":"code","source":["train_history = model.fit(\n","    x = {'input_ids':input_ids,'attention_mask':input_mask} ,\n","    y = categorical_train_emotions,\n","    epochs=1,\n","    batch_size = 36\n",")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"8rhjHtSIsuFe","executionInfo":{"status":"error","timestamp":1657185181601,"user_tz":-330,"elapsed":602,"user":{"displayName":"Pratik Hazarika","userId":"04317859684722913646"}},"outputId":"789c98fc-f708-4a37-8cbc-80ff016878aa"},"execution_count":125,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-125-aa7487457adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_history = model.fit(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# y = categorical_train_emotions,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# epochs=1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# batch_size = 36\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'NoneType'"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"82TsYB__61Fy"},"execution_count":null,"outputs":[]}]}