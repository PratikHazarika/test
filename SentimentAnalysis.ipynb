{"cells":[{"cell_type":"code","source":["!pip install transformers\n","\n","import pandas as pd \n","import numpy as np\n","import regex as re\n","import tensorflow as tf\n","\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.layers import Input, Dense, Dropout, GlobalMaxPool1D, Embedding, LSTM\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.metrics import CategoricalAccuracy\n","\n","from transformers import AutoTokenizer,TFBertModel\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive/', force_remount=True)"],"metadata":{"id":"z8tamXGM2asQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.layers import Input, Dense, Dropout, GlobalMaxPool1D, Embedding, LSTM, SpatialDropout1D, Bidirectional, Reshape, TimeDistributedDense"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"5tH61YnUE2zm","executionInfo":{"status":"error","timestamp":1658750470328,"user_tz":-330,"elapsed":555,"user":{"displayName":"Pratik Hazarika","userId":"05308899592677312661"}},"outputId":"658699a6-3001-4482-cd37-7e751076b0d9"},"execution_count":143,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-143-873c87bb48fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalMaxPool1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpatialDropout1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeDistributedDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mImportError\u001b[0m: cannot import name 'TimeDistributedDense' from 'tensorflow.keras.layers' (/usr/local/lib/python3.7/dist-packages/keras/api/_v2/keras/layers/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["# Loading dataset"],"metadata":{"id":"g_JgDlAC494s"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"npT7NqKb654I"},"outputs":[],"source":["df = pd.read_csv ('gdrive/MyDrive/Colab Notebooks/Sentiment Analysis/tweet_emotions.csv') "]},{"cell_type":"markdown","source":["# Cleaning the entire dataset\n","\n"],"metadata":{"id":"kKKeNi-u5guj"}},{"cell_type":"code","source":["df.drop('tweet_id', inplace = True, axis = 1)                 # removing tweet_id column\n","df.drop(df[(df['sentiment'] == 'empty')].index, inplace=True) # removing empty sentiment rows\n","\n","df.rename(columns = {'content':'sentence'}, inplace = True)   # renaming 'content' column to 'sentence'\n","\n","df.replace(to_replace = ['fun', 'happiness'], value = \"party\", inplace = True)               # fun, happiness <-> party\n","df.replace(to_replace = ['enthusiasm', 'surprise', 'love'], value = \"happy\", inplace = True) # enthusiasm, surprise, love <-> happy\n","df.replace(to_replace = ['sadness', 'anger', 'hate'], value = \"sad\", inplace = True)         # sadness, anger <-> sad\n","df.replace(to_replace = ['boredom', 'worry'], value = \"chill\", inplace = True)               # boredom, worry <-> chill\n","df.replace(to_replace = ['neutral', 'relief'], value = \"normal\", inplace = True)             # neutral, relief <-> normal\n","\n","df.dropna(inplace=True) # removing empty values"],"metadata":{"id":"TWOXpGQw5j2E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Cleaning the sentences"],"metadata":{"id":"csTQzB9g55-O"}},{"cell_type":"code","source":["sentences = df.sentence.tolist()\n","\n","for i in range(len(sentences)):\n","  sentences[i] = sentences[i].lower()\n","  sentences[i] = re.sub(r'http\\S+', \"\", sentences[i])\n","  sentences[i] = re.sub(r\"\\@\\w+\", \"\", sentences[i])\n","  sentences[i] = re.sub(r\"\\#\\w+\", \"\", sentences[i])\n","  sentences[i] = re.sub(r'[^\\w]', ' ', sentences[i])\n","  sentences[i] = re.sub(r\"\\............\\w+\", \"\", sentences[i])\n","  sentences[i] = re.sub(' +', ' ', sentences[i])\n","  sentences[i] = sentences[i].strip()"],"metadata":{"id":"bt_ekuM-6a_s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Splitting Train and Test Sentences"],"metadata":{"id":"gu3U4skH7YuZ"}},{"cell_type":"code","source":["train_sentences, test_sentences = train_test_split(sentences, test_size=0.2, shuffle=False) "],"metadata":{"id":"Y9eCdKY47VwJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uarl39sDn4Ar"},"source":["# Encoding Sentiments\n","Making a dictionary of all the sentiments in the dataset \\\n","Then mapping all the sentiments to the dictionary values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ux9kNdvXn6gr"},"outputs":[],"source":["sentiments_dict = {'party':0, 'happy':1, 'sad':2, 'chill':3, 'normal':4} # making sentiment dictionary\n","mapped_sentiments = df.sentiment.map(sentiments_dict) # mapping sentiments"]},{"cell_type":"markdown","metadata":{"id":"yWBXNOQZKTSu"},"source":["# Splitting Train and Test Sentiment \n","\n","Converting sentiments dictionary to numpy array to split train and test data \\\n","Encoding sentiments to vectors\\\n","Splitting train and test sentiments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GJTOL5DBCuj6"},"outputs":[],"source":["np_mapped_sentiments = mapped_sentiments.to_numpy() # converting sentiments to np array\n","encoded_mapped_sentiments = to_categorical(mapped_sentiments) # encoding sentiments \n","\n","mapped_train_sentiments, mapped_test_sentiments = train_test_split(np_mapped_sentiments, test_size=0.2, shuffle = False) \n","encoded_train_sentiments, encoded_test_sentiments = train_test_split(encoded_mapped_sentiments, test_size=0.2, shuffle = False) # splitting train and test sentiments"]},{"cell_type":"markdown","metadata":{"id":"pl6DhWvoiZSr"},"source":["# Tokenizing, Padding, Encoding, Embedding Sentences\n","\n","Using the pretrained Bert model called 'bert-base-cased' to preprocess the data \\\n","https://huggingface.co/bert-base-cased"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uRkQfWTTrWxN"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n","bert = TFBertModel.from_pretrained('bert-base-cased')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"evqS6C84MZNi"},"outputs":[],"source":["ls = [len(sentence.split()) for sentence in train_sentences] \n","max_len = int(np.percentile(ls, 98)) # finding the 98 percentile highest sentence length of the dataset\n","\n","x_train = tokenizer(\n","    text= train_sentences,\n","    add_special_tokens = True,\n","    max_length = max_len,\n","    truncation = True,\n","    padding = True, \n","    return_tensors = 'tf',\n","    return_token_type_ids = False,\n","    return_attention_mask = True,\n","    verbose = True)\n","\n","x_test = tokenizer(\n","    text = test_sentences,\n","    add_special_tokens = True,\n","    max_length = max_len,\n","    truncation = True,\n","    padding = True, \n","    return_tensors = 'tf',\n","    return_token_type_ids = False,\n","    return_attention_mask = True,\n","    verbose = True)"]},{"cell_type":"markdown","metadata":{"id":"09nxKGzn-XzG"},"source":["# Checkpoints\n","\n","Adding checkpoint paths to store save the weights of trained model after each epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5E82myNz-Voo"},"outputs":[],"source":["filepath=\"/content/gdrive/MyDrive/Colab Notebooks/Sentiment Analysis/checkpoints/cp1.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, mode='max')\n","callbacks_list = [checkpoint]"]},{"cell_type":"markdown","metadata":{"id":"TvqlqZZy8RsK"},"source":["# Making the model\n","\n","Making my model by adding layers to the neural network\n"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"ZV3wU2gIDII4","executionInfo":{"status":"ok","timestamp":1658747421343,"user_tz":-330,"elapsed":363,"user":{"displayName":"Pratik Hazarika","userId":"05308899592677312661"}}},"outputs":[],"source":["def create_model():\n","  # Input Layers\n","  input_ids_layer = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")       # input ids layer\n","  input_mask_layer = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\") # attendtion mask layer\n","  embeddings_layer = bert(input_ids_layer, attention_mask = input_mask_layer)[0]    # embeddings layer\n","\n","  # Hidden Layers\n","  hidden_layer_1 = SpatialDropout1D()(embeddings_layer) \n","  hidden_layer_2 = Dense(64, activation='relu')(hidden_layer_1)\n","  hidden_layer_3 = Dropout(0.5)(hidden_layer_2)\n","  hidden_layer_4 = Dense(16,activation = 'relu')(hidden_layer_3)\n","  hidden_layer_5 = Dropout(0.5)(hidden_layer_4)\n","  hidden_layer_6 = LSTM(64, dropout=0.2, recurrent_dropout=0.2)(hidden_layer_5)\n","\n","  # Output Layer\n","  output_layer = Dense(5,activation = 'softmax')(hidden_layer_6) # output layer\n","\n","  # Models\n","  model = tf.keras.Model(inputs=[input_ids_layer, input_mask_layer], outputs=output_layer) # model\n","  model.layers[2].trainable = True\n","\n","  return model"]},{"cell_type":"code","source":["# def create_model():\n","#   # Input Layers\n","#   input_ids_layer = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")       # input ids layer\n","#   input_mask_layer = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\") # attendtion mask layer\n","#   l = bert(input_ids_layer, attention_mask = input_mask_layer)[0]    # embeddings layer\n","#   print(l.shape)\n","#   # Hidden Layers\n","#   #l = GlobalMaxPool1D()(l) \n","#   #print(type(l))\n","#   # l = SpatialDropout1D(0.4)(l)\n","#   l = Dense(64, activation='relu')(l)\n","#   l = Dropout(0.5)(l)\n","#   l = Dense(16,activation = 'relu')(l)\n","#   l = Dropout(0.5)(l) \n","#   #l = Reshape((None,1, 16), input_shape=(None,16))\n","#   print(type(l))\n","#   # l = TimeDistributedDense(10,input_dim=10)\n","#   # l = LSTM(64, dropout=0.2, recurrent_dropout=0.2)(l)\n","#   # l = LSTM(32, dropout=0.2, recurrent_dropout=0.2, input_shape=(None,16))(l)\n","#   # l = Bidirectional(LSTM(32))(l)\n","\n","#   # Output Layer\n","#   output_layer = Dense(5,activation = 'softmax')(l) # output layer\n","\n","#   # Models\n","#   model = tf.keras.Model(inputs=[input_ids_layer, input_mask_layer], outputs=output_layer) # model\n","#   model.layers[2].trainable = True\n","\n","#   return model\n","\n","\n","# model = create_model()\n","# model = compile_model(model)\n","# model.summary()"],"metadata":{"id":"wgvWK1N-AkCZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658752371800,"user_tz":-330,"elapsed":2719,"user":{"displayName":"Pratik Hazarika","userId":"05308899592677312661"}},"outputId":"9b21ce2e-9c56-4734-c275-26c776b1401b"},"execution_count":166,"outputs":[{"output_type":"stream","name":"stdout","text":["(None, 28, 768)\n","<class 'keras.engine.keras_tensor.KerasTensor'>\n","Model: \"model_15\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_ids (InputLayer)         [(None, 28)]         0           []                               \n","                                                                                                  \n"," attention_mask (InputLayer)    [(None, 28)]         0           []                               \n","                                                                                                  \n"," tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n","                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n","                                tentions(last_hidde                                               \n","                                n_state=(None, 28,                                                \n","                                768),                                                             \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," dense_151 (Dense)              (None, 28, 64)       49216       ['tf_bert_model[79][0]']         \n","                                                                                                  \n"," dropout_148 (Dropout)          (None, 28, 64)       0           ['dense_151[0][0]']              \n","                                                                                                  \n"," dense_152 (Dense)              (None, 28, 16)       1040        ['dropout_148[0][0]']            \n","                                                                                                  \n"," dropout_149 (Dropout)          (None, 28, 16)       0           ['dense_152[0][0]']              \n","                                                                                                  \n"," dense_153 (Dense)              (None, 28, 5)        85          ['dropout_149[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 108,360,613\n","Trainable params: 108,360,613\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"TWtS-6DJFkW_"},"source":["# Compiling the model\n","Compiling the model using:\n","- Adam optimizer (experimented with the hyperparameters to find the best one)\n","- Categorical Cross Entropy (I'm doing multi-class sentiment analysis)\n","- Categorical Accuracy (using balanced accuracy to see the accuracy of all the classes)\n"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"4cQwIC8sFj1C","executionInfo":{"status":"ok","timestamp":1658747493091,"user_tz":-330,"elapsed":4,"user":{"displayName":"Pratik Hazarika","userId":"05308899592677312661"}}},"outputs":[],"source":["def compile_model(model):\n","  optimizer = Adam(\n","    learning_rate=5e-05,\n","    epsilon=1e-08,\n","    decay=0.01,\n","    clipnorm=1.0\n","  )\n","  \n","  loss = CategoricalCrossentropy(from_logits = True)\n","  metric = CategoricalAccuracy('balanced_accuracy'),\n","\n","  model.compile(\n","      optimizer = optimizer,\n","      loss = loss, \n","      metrics = metric\n","  )\n","\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"0n3dTD8G59QS"},"source":["# Training the model"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"wBGc4QYRMkY9","executionInfo":{"status":"ok","timestamp":1658747494498,"user_tz":-330,"elapsed":1,"user":{"displayName":"Pratik Hazarika","userId":"05308899592677312661"}}},"outputs":[],"source":["def train_model(model):\n","  model.fit(\n","      x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']}, \n","      y = encoded_train_sentiments,\n","      validation_data = ({'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']}, encoded_test_sentiments),\n","      epochs= 7,\n","      batch_size= 36,\n","      callbacks = callbacks_list\n","  )\n","\n","  return model"]},{"cell_type":"code","source":["model = create_model()\n","model = compile_model(model)\n","model = train_model(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"id":"8RJE2AO5_7FZ","executionInfo":{"status":"error","timestamp":1658747498390,"user_tz":-330,"elapsed":2415,"user":{"displayName":"Pratik Hazarika","userId":"05308899592677312661"}},"outputId":"32bbb025-b7b9-4563-8b64-82537c36efc3"},"execution_count":86,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-86-13e7a6cf28ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-83-dfc0bcfa9d29>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m176\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m# Output Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\u001b[0m\u001b[1;32m    215\u001b[0m                          \u001b[0;34m'is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                          \u001b[0;34mf'expected ndim={spec.ndim}, found ndim={ndim}. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"lstm_3\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 16)"]}]},{"cell_type":"markdown","metadata":{"id":"9WGaJIeZ9sbX"},"source":["# Loading checkpoints"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"f-YA8FAg9cR7"},"outputs":[],"source":["model = create_model()\n","model.load_weights(\"/content/gdrive/MyDrive/Colab Notebooks/Sentiment Analysis/checkpoints/cp1.hdf5\")\n","model = compile_model(model)"]},{"cell_type":"markdown","source":[""],"metadata":{"id":"ICnS-du4_0wq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_E-_u7nChSAW"},"outputs":[],"source":["filepath=\"/content/gdrive/MyDrive/Colab Notebooks/Sentiment Analysis/checkpoints/cp2.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, mode='max')\n","callbacks_list = [checkpoint]\n","model = train_model(model)\n","model = create_model()\n","model.load_weights(\"/content/gdrive/MyDrive/Colab Notebooks/Sentiment Analysis/checkpoints/cp2.hdf5\")\n","model = compile_model(model)"]},{"cell_type":"markdown","metadata":{"id":"UBQyOqDd2Kc5"},"source":["# Saving Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rPm3G9uCNSQS"},"outputs":[],"source":["model.save('gdrive/MyDrive/Colab Notebooks/Sentiment Analysis/mymodel/model.h5')"]},{"cell_type":"markdown","source":["# Predicting the mood"],"metadata":{"id":"9NrycY9Y-X2C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ma3FBjC_thTy"},"outputs":[],"source":["def get_mood():\n","  threshold_pred = 67.8 # value calculated after running the program\n","  texts = input(str('Hey! How are you today? '))\n","\n","  x_val = tokenizer(\n","      text=texts,\n","      add_special_tokens=True,\n","      max_length=max_len,\n","      truncation=True,\n","      padding='max_length', \n","      return_tensors='tf',\n","      return_token_type_ids = False,\n","      return_attention_mask = True,\n","      verbose = True\n","      ) \n","\n","  validation = model.predict({'input_ids':x_val['input_ids'],'attention_mask':x_val['attention_mask']}) * 100\n","  predicted_sentiments = dict()\n","\n","  for key, value in zip(sentiments_dict.keys(), validation[0]):\n","      predicted_sentiments[key] = value\n","\n","  predicted_mood = max(zip(predicted_sentiments.values(), predicted_sentiments.keys()))[1]\n","  predicted_mood_value = max(zip(predicted_sentiments.values(), predicted_sentiments.keys()))[0]\n","\n","  if predicted_mood_value < threshold_pred:\n","    return \"I'm sorry! I'm not sure how you feel\"\n","\n","  return predicted_mood\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TEC8uT5fTnWk"},"outputs":[],"source":["get_mood()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"SentimentAnalysis.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}